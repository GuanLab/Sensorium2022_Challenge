{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageStat\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.models import convnext_large, ConvNeXt_Large_Weights\n",
    "\n",
    "from neuralpredictors.measures.np_functions import corr, fev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_agg(series):\n",
    "    array = np.array([ast.literal_eval(x) for x in series])\n",
    "    array = np.mean(array, axis=0)\n",
    "    return array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_to_yolo_bbox(bbox, w, h):\n",
    "    # xmin, ymin, xmax, ymax\n",
    "    x_center = ((bbox[2] + bbox[0]) / 2) / w\n",
    "    y_center = ((bbox[3] + bbox[1]) / 2) / h\n",
    "    width = (bbox[2] - bbox[0]) / w\n",
    "    height = (bbox[3] - bbox[1]) / h\n",
    "    return [x_center, y_center, width, height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"pretrain_21067-10-18\", \"pretrain_23343-5-17\", \"pretrain_22846-10-16\",\n",
    "            \"pretrain_23656-14-22\", \"pretrain_23964-4-22\", \"sensorium_26872-17-20\",\n",
    "            \"sensorium+_27204-5-13\"]\n",
    "data_keys = [key.split(\"_\")[1] for key in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_image_id = {}\n",
    "for data_key in data_keys[:5]:\n",
    "    frame_image_id[data_key] = np.load(f\"./dataset/pretrain_{data_key}/meta/trials/frame_image_id.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_gt = {}\n",
    "for data_key in data_keys[:5]:\n",
    "    pred = pd.read_csv(f\"../sensorium/preds_gt/{data_key}/submission_file_live_test.csv\")\n",
    "    gt = pd.read_csv(f\"../sensorium//preds_gt/{data_key}/ground_truth_file_test.csv\")\n",
    "    pred = pd.merge(pred, gt, how=\"left\", on=[\"trial_indices\", \"image_ids\", \"neuron_ids\"])\n",
    "    preds_gt[data_key] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds_gt = preds_gt.copy()\n",
    "for data_key in data_keys[:5]:\n",
    "    avg_preds_gt[data_key] = avg_preds_gt[data_key].groupby(\"image_ids\")\\\n",
    "        .agg({\"prediction\": custom_agg, \n",
    "              \"responses\": custom_agg,\n",
    "              \"neuron_ids\": custom_agg})\n",
    "    avg_preds_gt[data_key].reset_index(inplace=True)\n",
    "    \n",
    "    mean_responses = np.vstack(avg_preds_gt[data_key].responses)\n",
    "    mean_predictions = np.vstack(avg_preds_gt[data_key].prediction)\n",
    "    correlation = corr(mean_responses, mean_predictions, axis=1)\n",
    "    avg_preds_gt[data_key][\"correlation\"] = correlation\n",
    "    \n",
    "    true_image_ids = [np.where(frame_image_id[data_key] == the_id)[0][0] for the_id in avg_preds_gt[data_key].image_ids]\n",
    "    avg_preds_gt[data_key][\"true_image_ids\"] = true_image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(x: list):\n",
    "    return [np.min(x), np.median(x), np.max(x), np.mean(x), np.std(x)]\n",
    "\n",
    "# statistically summarize the response for each image\n",
    "merge_preds_gt = pd.DataFrame()\n",
    "for data_key in data_keys[:5]:\n",
    "    df = preds_gt[data_key].copy()\n",
    "    df[\"dataset\"] = data_key\n",
    "    merge_preds_gt = pd.concat([merge_preds_gt, df], ignore_index=True)\n",
    "    \n",
    "response_summary = [summary(ast.literal_eval(x)) for x in merge_preds_gt.responses.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"response_min\", \"response_median\", \"response_max\", \"response_mean\", \"response_std\"]\n",
    "response_summary = np.array(response_summary)\n",
    "response_summary = pd.DataFrame(response_summary, columns=cols)\n",
    "pd.concat([merge_preds_gt, response_summary], axis=1)[[\"image_ids\", \"dataset\"]+cols].to_csv(\"image_response_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistically summarize the response for each image after merging the repeats\n",
    "merge_avg_preds_gt = pd.DataFrame()\n",
    "for data_key in data_keys[:5]:\n",
    "    df = avg_preds_gt[data_key].copy()\n",
    "    df[\"dataset\"] = data_key\n",
    "    merge_avg_preds_gt = pd.concat([merge_avg_preds_gt, df], ignore_index=True)\n",
    "    \n",
    "cols = [\"response_min\", \"response_median\", \"response_max\", \"response_mean\", \"response_std\"]\n",
    "response_summary = np.array([summary(x) for x in merge_avg_preds_gt.responses.values])\n",
    "response_summary = pd.DataFrame(response_summary, columns=cols)\n",
    "\n",
    "pd.concat([merge_avg_preds_gt, response_summary], axis=1)[[\"image_ids\", \"dataset\"]+cols].to_csv(\"image_mergeRep_response_summary.csv\", index=False)\n",
    "\n",
    "cols = [\"preds_min\", \"preds_median\", \"preds_max\", \"preds_mean\", \"preds_std\"]\n",
    "preds_summary = np.array([summary(x) for x in merge_avg_preds_gt.prediction.values])\n",
    "preds_summary = pd.DataFrame(preds_summary, columns=cols)\n",
    "\n",
    "pd.concat([merge_avg_preds_gt, preds_summary], axis=1)[[\"image_ids\", \"dataset\"]+cols].to_csv(\"image_mergeRep_preds_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation for the test images in each dataset\n",
    "merge_preds_gt = pd.DataFrame()\n",
    "for data_key in data_keys[:5]:\n",
    "    df = avg_preds_gt[data_key].copy()\n",
    "    df[\"dataset\"] = data_key\n",
    "    merge_preds_gt = pd.concat([merge_preds_gt, df], ignore_index=True)\n",
    "    \n",
    "merge_preds_gt = merge_preds_gt[[\"image_ids\", \"correlation\", \"dataset\"]]\n",
    "merge_preds_gt.to_csv(\"outputs_model_with_image/image_performance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate image complexity use the spatial information\n",
    "# https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6603194\n",
    "SI_means = []\n",
    "for trial_id in avg_preds_gt[\"21067-10-18\"].image_ids:\n",
    "    img = cv2.imread(f\"./outputs_model_with_image/images/{trial_id}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    # Calculate the gradient magnitude\n",
    "    SI_r = np.sqrt(sobelx**2 + sobely**2)\n",
    "    SI_means.append(np.mean(SI_r))\n",
    "    \n",
    "brightness = []\n",
    "contrast = []\n",
    "for trial_id in avg_preds_gt[\"21067-10-18\"].image_ids:\n",
    "    img = Image.open(f\"./test_images/{trial_id}.png\")\n",
    "    stat = ImageStat.Stat(img)\n",
    "    brightness.append(stat.mean[0])\n",
    "    contrast.append(stat.stddev[0])\n",
    "    \n",
    "    # brightness.append(calculate_brightness(img))\n",
    "    \n",
    "image_complexity = pd.DataFrame({\"image_ids\": avg_preds_gt[\"21067-10-18\"].image_ids,\n",
    "                                 \"Complexity\": SI_means,\n",
    "                                 \"Brightness\": brightness,\n",
    "                                 \"Contrast\": contrast})\n",
    "image_complexity.to_csv(\"./outputs_model_with_image/image_complexity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengkw/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# generate category info for the test images\n",
    "# still need manual input...\n",
    "weights = ConvNeXt_Large_Weights.DEFAULT\n",
    "model = convnext_large(weights=weights)\n",
    "model.eval()\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "categories = []\n",
    "for image_id in avg_preds_gt[\"21067-10-18\"].true_image_ids:\n",
    "    img = read_image(f\"./images_png/pretrain_21067-10-18/data/images/{image_id}.png\", \n",
    "                    ImageReadMode.RGB)\n",
    "\n",
    "    batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "    prediction = model(batch).squeeze(0).softmax(0)\n",
    "    class_ids = torch.topk(prediction, k=3).indices\n",
    "    scores = torch.topk(prediction, k=3).values\n",
    "    category_name = [weights.meta[\"categories\"][class_id] for class_id in class_ids]\n",
    "    categories.append(\", \".join(category_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_category = pd.DataFrame({\"trial_ids\": avg_preds_gt[\"21067-10-18\"].image_ids,\n",
    "                               \"inferred_category\": categories})\n",
    "image_category.to_csv(\"./outputs_model_with_image/category.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfee84e221173515dcc4292e621f15adf0cc7ab56cc192320f25767007d11a6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
